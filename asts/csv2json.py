import argparse
import csv
import json
import os
import sys

sys.path.append('..')
from tools.datatools import load_all_pids

# This takes the csv file generated by astminer and converts it to json, where each set of the data is in it's own dict.
csv.field_size_limit(int(sys.maxsize / 5000000000))


def main(args):
    print(str(args)[16:-2])
    train_dict = {}
    dev_dict = {}
    test_dict = {}
    train, dev, test = load_all_pids(args.data)
    ast_path = os.path.join(args.data, 'ast', 'cpp', 'asts.csv')
    with open(ast_path, 'r') as fc:
        data = dict(csv.reader(fc))
    for key in list(data.keys()):
        try:
            new_key = int(key[:-4].split('/')[-1])
        except ValueError:  # Skips tmp files that are generated by astminer.
            print(f"Unneeded key found. Skipping {key}.")
            continue
        if new_key in train: # Checks which subset each file belongs to.
            train_dict[new_key] = data.pop(key)
        elif new_key in dev:
            dev_dict[new_key] = data.pop(key)
        elif new_key in test:
            test_dict[new_key] = data.pop(key)
        else:
            raise Exception(f"Unable to place key into a dictionary:\n{new_key}")
    print("Keys skipped: {}".format(len(data)))
    print("Train keys: {}".format(len(train_dict)))
    print("Dev keys: {}".format(len(dev_dict)))
    print("Test keys: {}".format(len(test_dict)))
    ast_dict = {'train': train_dict, 'dev': dev_dict, 'test': test_dict}
    json_file = os.path.join(args.data, 'ast', 'ast.json')
    with open(json_file, 'w')as fj:
        json.dump(ast_dict, fj, indent='\t')
    print("ASTs written to {}".format(json_file))


if __name__ == '__main__':
    parser = argparse.ArgumentParser(fromfile_prefix_chars='@')
    parser.add_argument('-d',
                        '--data',
                        type=str,
                        default=r'../data_dir',
                        help='Path to the data directory.')

    args = parser.parse_args()
    main(args)
